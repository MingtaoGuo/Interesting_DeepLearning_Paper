# Summary of deep learning papers
Summarize some interesting paper about computer vision

### Image Classification Methods
:sunny: (LeNet)[Gradient-based learning applied to document recognition] [[Paper](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)]

:sunny: (AlexNet)[ImageNet Classification with Deep Convolutional Neural Networks] [NIPS 2012][[Paper](http://xanadu.cs.sjsu.edu/~drtylin/classes/cs267_old/ImageNet%20DNN%20NIPS2012(2).pdf)][[Code](https://github.com/hjptriplebee/AlexNet_with_tensorflow)]

:sunny: (VGGNet)[Very Deep Convolutional Networks for Large-Scale Image Recognition] [arXiv][[Paper](http://cn.arxiv.org/pdf/1409.1556v6)][[Code](https://github.com/machrisaa/tensorflow-vgg)]

:sunny: (GoogLeNet)[Going deeper with convolutions] [CVPR 2015][[Paper](http://cn.arxiv.org/pdf/1409.4842v1)][[Code](https://github.com/conan7882/GoogLeNet-Inception-tf)]

:sunny: (ResNet)[Deep Residual Learning for Image Recognition] [CVPR 2016][[Paper](http://cn.arxiv.org/pdf/1512.03385v1)][[Code](https://github.com/ry/tensorflow-resnet)]

:sunny: (ResNeXt)[Aggregated Residual Transformations for Deep Neural Networks] [CVPR 2017][[Paper](http://cn.arxiv.org/pdf/1611.05431v2)][[Code](https://github.com/taki0112/ResNeXt-Tensorflow)]

:sunny: (DenseNet)[Densely Connected Convolutional Networks] [CVPR 2017][[Paper](http://cn.arxiv.org/pdf/1608.06993v5)][[Code](https://github.com/YixuanLi/densenet-tensorflow)]

:sunny: (Inception-v4)[Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning] [AAAI 2017][[Paper](http://cn.arxiv.org/pdf/1602.07261v2)][[Code](https://github.com/titu1994/Inception-v4)]

:sunny: (Inception-v3)[Rethinking the Inception Architecture for Computer Vision] [CVPR 2016][[Paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)][[Code](https://github.com/smichalowski/google_inception_v3_for_caffe)]

:sunny: (Xception)[Xception: Deep Learning with Depthwise Separable Convolutions] [CVPR 2017][[Paper](http://cn.arxiv.org/pdf/1610.02357v3)][[Code](https://github.com/kwotsin/TensorFlow-Xception)]

:sunny: (ShuffleNet)[ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices] [arXiv][[Paper](http://cn.arxiv.org/pdf/1707.01083v2)][[Code](https://github.com/MG2033/ShuffleNet)]

:sunny: (MobileNets)[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications] [arXiv][[Paper](http://cn.arxiv.org/pdf/1704.04861v1)][[Code](https://github.com/Zehaos/MobileNet)]

:sunny: (SENet)[Squeeze-and-Excitation Networks] [CVPR 2018][[Paper](http://cn.arxiv.org/pdf/1709.01507)][[Code](https://github.com/taki0112/SENet-Tensorflow)]

### Normalization Methods

:moon: (Batch Normalization)[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift] [ICML][[Paper](http://cn.arxiv.org/pdf/1502.03167v3)]

:moon: (Instance Normalization)[Instance Normalization: The Missing Ingredient for Fast Stylization] [arXiv][[Paper](http://cn.arxiv.org/pdf/1607.08022v3)][[Code](https://github.com/ryankiros/layer-norm)]

:moon: (Layer Normalization)[Layer Normalization] [arXiv][[Paper](https://arxiv.org/pdf/1607.06450v1.pdf)]

:moon: (Group Normalization)[Group Normalization] [arXiv][[Paper](https://arxiv.org/pdf/1803.08494.pdf)][[Code](https://github.com/shaohua0116/Group-Normalization-Tensorflow)]

:moon: (Switchable Normalization)[Differentiable Learning-to-Normalize via Switchable Normalization] [arXiv][[Paper](https://arxiv.org/pdf/1806.10779.pdf)][[Code](https://github.com/taki0112/Switchable_Normalization-Tensorflow)]

:moon: (Instance-Batch Normalization)[Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net] [arXiv][[Paper](https://arxiv.org/pdf/1807.09441.pdf)][[Code](https://github.com/XingangPan/IBN-Net)]

### Activation Functions

:star: (ReLU)[Rectified linear units improve restricted boltzmann machines] [ICML][[Paper](http://www.cs.utoronto.ca/~hinton/absps/reluICML.pdf)]

:star: (Noisy ReLU)[Deep Belief Networks on CIFAR-10] [arXiv][[Paper](http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdfConvolutional)]

:star: (Leaky ReLU)[Rectifier Nonlinearities Improve Neural Network Acoustic Models] [ICML 2013][[Paper](http://robotics.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)]

:star: (eLU)[Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)] [arXiv][[Paper](http://cn.arxiv.org/pdf/1511.07289v5)]

:star: (SeLU)[Self-Normalizing Neural Networks] [NIPS 2017][[Paper](http://cn.arxiv.org/pdf/1706.02515)][[Code](https://github.com/dannysdeng/selu)]

:star: (PReLU)[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification] [ICCV 2015][[Paper](http://cn.arxiv.org/pdf/1502.01852v1)]

:star: (Maxout)[Maxout Networks] [JMLR 2013][[Paper](http://cn.arxiv.org/pdf/1302.4389v4)]

:star: (Swish)[Searching for Activation Functions] [arXiv][[Paper](https://arxiv.org/pdf/1710.05941.pdf)]

### Generative Adversarial Networks Theory

:blossom: (GAN)[Generative adversarial nets] [NIPS 2014][[Paper](http://cn.arxiv.org/pdf/1406.2661)][[Code](https://github.com/goodfeli/adversarial)]

:blossom: (cGAN)[Conditional Generative Adversarial Nets] [arXiv][[Paper](http://cn.arxiv.org/pdf/1411.1784)][[Code](https://github.com/YadiraF/GAN)]

:blossom: (DCGAN)[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] [arXiv][[Paper](http://cn.arxiv.org/pdf/1511.06434)][[Code](https://github.com/MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_RaSGAN_TensorFlow)]

:blossom: (LAPGAN)[Deep generative image models using a Laplacian pyramid of adversarial networks] [NIPS 2015][[Paper](http://cn.arxiv.org/pdf/1506.05751v1)][[Code](https://github.com/AaronYALai/Generative_Adversarial_Networks_PyTorch)]

:blossom: (Semi-Supervised GAN)[Improved Techniques for Training GANs] [NIPS 2016][[Paper](http://cn.arxiv.org/pdf/1606.03498)][[Code](https://github.com/LDOUBLEV/semi-supervised-GAN)]

:blossom: (Info GAN)[InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets] [NIPS 2016][[Paper](http://cn.arxiv.org/pdf/1606.03657v1)][[Code](https://github.com/JonathanRaiman/tensorflow-infogan)]

:blossom: (LSGAN)[Least Squares Generative Adversarial Networks] [ICCV 2017][[Paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf)][[Code](https://github.com/MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_RaSGAN_TensorFlow)]

:blossom: (WGAN)[Wasserstein Generative Adversarial Networks] [ICML 2017][[Paper](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf)][[Code](https://github.com/jiamings/wgan)]

:blossom: (WGAN-GP)[Improved Training of Wasserstein GANs] [NIPS 2017][[Paper](http://cn.arxiv.org/pdf/1704.00028v3)][[Code](https://github.com/MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_RaSGAN_TensorFlow)]

:blossom: (EBGAN)[Energy-based Generative Adversarial Network] [arXiv][[Paper](http://cn.arxiv.org/pdf/1609.03126)][[Code](https://github.com/buriburisuri/ebgan)]

:blossom: (BEGAN)[BEGAN: Boundary Equilibrium Generative Adversarial Networks] [arXiv][[Paper](http://cn.arxiv.org/pdf/1703.10717v4)][[Code](https://github.com/carpedm20/BEGAN-tensorflow)]

:blossom: (PG-GAN)[Progressive Growing of GANs for Improved Quality, Stability, and Variation] [arXiv][[Paper](http://cn.arxiv.org/pdf/1710.10196v3)][[Code](https://github.com/nashory/pggan-pytorch)]

:blossom: (SNGAN)[Spectral Normalization for Generative Adversarial Networks] [arXiv][[Paper](http://cn.arxiv.org/pdf/1802.05957)][[Code](https://github.com/pfnet-research/sngan_projection)]

:blossom: (DRAGAN)[On Convergence and Stability of GANs] [arXiv][[Paper](http://cn.arxiv.org/pdf/1705.07215v5)][[Code](https://github.com/jfsantos/dragan-pytorch)]

:blossom: (Relativistic GAN)[The relativistic discriminator: a key element missing from standard GAN] [arXiv][[Paper](http://cn.arxiv.org/pdf/1807.00734.pdf)][[Code](https://github.com/AlexiaJM/RelativisticGAN)]

:blossom: (cGAN with projection disc)[cGANs with projection discriminator] [arXiv][[Paper](https://arxiv.org/pdf/1802.05637.pdf)][[Code](https://github.com/pfnet-research/sngan_projection)]

:blossom: (BigGAN)[Large Scale GAN Training for High Fidelity Natural Image Synthesis] [arXiv][[Paper](https://arxiv.org/pdf/1809.11096.pdf)][[Code]()]

:blossom: (SAGAN)[Self-Attention Generative Adversarial Networks] [arXiv][[Paper](https://arxiv.org/pdf/1805.08318.pdf)][[Code]()]

### Image-to-Image Translation
:bug: (pix2pix)[Image-to-Image Translation with Conditional Adversarial Networks] [CVPR 2017][[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf)][[Code](https://github.com/phillipi/pix2pix)]

:bug: (pix2pixHD)[High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs] [CVPR 2018][[Paper](http://cn.arxiv.org/pdf/1711.11585)][[Code](https://github.com/NVIDIA/pix2pixHD)]

:bug: (CycleGAN)[Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks] [ICCV 2017][[Paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf)][[Code](https://github.com/junyanz/CycleGAN)]

:bug: [Unsupervised Attention-guided Image to Image Translation] [arXiv][[Paper](http://cn.arxiv.org/pdf/1806.02311)][[Code](https://github.com/AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation)]

:bug: (DiscoGAN)[Learning to Discover Cross-Domain Relations with Generative Adversarial Networks] [ICML 2017][[Paper](http://cn.arxiv.org/pdf/1703.05192)][[Code](https://github.com/SKTBrain/DiscoGAN)]

:bug: (UNIT)[Unsupervised Image-to-Image Translation Networks] [NIPS 2017][[Paper](http://papers.nips.cc/paper/6672-unsupervised-image-to-image-translation-networks.pdf)][[Code](https://github.com/taki0112/UNIT-Tensorflow)]

:bug: (MUNIT)[Multimodal Unsupervised Image-to-Image Translation] [arXiv][[Paper](https://arxiv.org/pdf/1804.04732.pdf)][[Code](https://github.com/NVlabs/MUNIT)]

:bug: (BicycleGAN)[Toward Multimodal Image-to-Image Translation] [NIPS 2017][[Paper](http://cn.arxiv.org/pdf/1711.11586)][[Code](https://github.com/junyanz/BicycleGAN)]

:bug: (StarGAN)[StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation] [CVPR 2018][[Paper](http://cn.arxiv.org/pdf/1711.09020)][[Code](https://github.com/taki0112/StarGAN-Tensorflow)]

:bug: (RecycleGAN)[Recycle-GAN: Unsupervised Video Retargeting] [ECCV 2018][[Paper](http://cn.arxiv.org/pdf/1808.05174v1)][[Code](https://github.com/SunnerLi/RecycleGAN)]

### Style Transfer
:whale: (Gatys)[A Neural Algorithm of Artistic Style] [[Paper](http://cn.arxiv.org/pdf/1508.06576)]

:whale: (Johnson)[Perceptual Losses for Real-Time Style Transfer and Super-Resolution] [[Paper](http://cn.arxiv.org/pdf/1603.08155)]

:whale: [Universal Style Transfer via Feature Transforms] [[Paper](http://cn.arxiv.org/pdf/1705.08086)]

:whale: [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization] [[Paper](http://cn.arxiv.org/pdf/1703.06868)]

:whale: [Visual attribute transfer through deep image analogy] [[Paper](http://cn.arxiv.org/pdf/1705.01088)]

:whale: [Arbitrary Style Transfer with Deep Feature Reshuffle] [[Paper](http://cn.arxiv.org/pdf/1805.04103)]

:whale: [Artistic style transfer for videos] [[Paper](http://cn.arxiv.org/pdf/1604.08610.pdf)]

:whale: [Characterizing and Improving Stability in Neural Style Transfer] [[Paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Gupta_Characterizing_and_Improving_ICCV_2017_paper.pdf)]

:whale: [Controlling Perceptual Factors in Neural Style Transfer] [[Paper](http://cn.arxiv.org/pdf/1611.07865)]

:whale: [Deep Photo Style Transfer] [[Paper](http://cn.arxiv.org/pdf/1703.07511)]

:whale: [Fast Patch-based Style Transfer of Arbitrary Style] [[Paper](http://cn.arxiv.org/pdf/1612.04337.pdf)]

:whale: [Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis] [[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Ulyanov_Improved_Texture_Networks_CVPR_2017_paper.pdf)]

:whale: [Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer] [[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Multimodal_Transfer_A_CVPR_2017_paper.pdf)]

:whale: [StyleBank: An Explicit Representation for Neural Image Style Transfer] [[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_StyleBank_An_Explicit_CVPR_2017_paper.pdf)]

:whale: [CartoonGAN: generative adversarial networks for photo cartoonization] [[Paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf)]

:whale: [Visual Attribute Transfer through Deep Image Analogy] [[Paper](http://cn.arxiv.org/pdf/1705.01088)]

:whale: [A learned representation for artistic style] [[Paper](https://arxiv.org/pdf/1610.07629.pdf)]

### Face Attribute Manipulation
:alien: [Deep Feature Interpolation for Image Content Changes] [[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Upchurch_Deep_Feature_Interpolation_CVPR_2017_paper.pdf)]

:alien: [Autoencoding beyond pixels using a learned similarity metric] [[Paper](http://cn.arxiv.org/pdf/1512.09300)]

:alien: [Convolutional Network for Attribute-driven and Identity-preserving Human Face Generation] [[Paper](http://cn.arxiv.org/pdf/1608.06434)]

:alien: [Deep Identity-aware Transfer of Facial Attributes] [[Paper](http://cn.arxiv.org/pdf/1610.05586)]

:alien: [Learning Residual Images for Face Attribute Manipulation] [[Paper](http://cn.arxiv.org/pdf/1612.05363)]

:alien: (StarGAN)[StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation] [[Paper](http://cn.arxiv.org/pdf/1711.09020)]
### Image Inpainting
:eyes: [Context Encoders: Feature Learning by Inpainting] [[Paper](http://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf)]

:eyes: [Semantic Image Inpainting with Deep Generative Models] [[Paper](http://cn.arxiv.org/pdf/1607.07539)]

:eyes: [High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis] [[Paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_High-Resolution_Image_Inpainting_CVPR_2017_paper.pdf)]

:eyes: [Globally and locally consistent image completion] [[Paper](http://hi.cs.waseda.ac.jp/~iizuka/projects/completion/data/completion_sig2017.pdf)]

:eyes: [Generative Image Inpainting with Contextual Attention] [[Paper](http://cn.arxiv.org/pdf/1801.07892v2)]


## To be continued.

